{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mjzkrM3ZpqwK",
        "outputId": "bad2258e-c020-4d30-a1ae-1b14387b48f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hello.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile hello.cpp\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define INPUT_SIZE 1000\n",
        "#define HIDDEN_SIZE 256\n",
        "#define OUTPUT_SIZE 100\n",
        "#define LEARNING_RATE 0.001\n",
        "#define ITERATIONS 500\n",
        "\n",
        "// Define neural network parameters\n",
        "float input[INPUT_SIZE];\n",
        "float hidden_weights[INPUT_SIZE][HIDDEN_SIZE];\n",
        "float hidden_bias[HIDDEN_SIZE];\n",
        "float hidden_output[HIDDEN_SIZE];\n",
        "float output_weights[HIDDEN_SIZE][OUTPUT_SIZE];\n",
        "float output_bias[OUTPUT_SIZE];\n",
        "float output[OUTPUT_SIZE];\n",
        "\n",
        "// Forward pass of the neural network\n",
        "void forward_pass() {\n",
        "    // Compute hidden layer output\n",
        "    for (int i = 0; i < HIDDEN_SIZE; i++) {\n",
        "        float sum = 0.0;\n",
        "        for (int j = 0; j < INPUT_SIZE; j++) {\n",
        "            sum += input[j] * hidden_weights[j][i];\n",
        "        }\n",
        "        hidden_output[i] = sum + hidden_bias[i];\n",
        "        hidden_output[i] = (hidden_output[i] > 0) ? hidden_output[i] : 0; // ReLU activation\n",
        "    }\n",
        "\n",
        "    // Compute output layer output\n",
        "    for (int i = 0; i < OUTPUT_SIZE; i++) {\n",
        "        float sum = 0.0;\n",
        "        for (int j = 0; j < HIDDEN_SIZE; j++) {\n",
        "            sum += hidden_output[j] * output_weights[j][i];\n",
        "        }\n",
        "        output[i] = sum + output_bias[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Backward pass of the neural network\n",
        "void backward_pass(float target[OUTPUT_SIZE]) {\n",
        "    // Compute output layer gradients\n",
        "    for (int i = 0; i < OUTPUT_SIZE; i++) {\n",
        "        float error = output[i] - target[i];\n",
        "        for (int j = 0; j < HIDDEN_SIZE; j++) {\n",
        "            output_weights[j][i] -= LEARNING_RATE * error * hidden_output[j];\n",
        "        }\n",
        "        output_bias[i] -= LEARNING_RATE * error;\n",
        "    }\n",
        "\n",
        "    // Compute hidden layer gradients\n",
        "    for (int i = 0; i < HIDDEN_SIZE; i++) {\n",
        "        float error = 0.0;\n",
        "        for (int j = 0; j < OUTPUT_SIZE; j++) {\n",
        "            error += (output[j] - target[j]) * output_weights[i][j];\n",
        "        }\n",
        "        error *= (hidden_output[i] > 0) ? 1 : 0; // ReLU derivative\n",
        "        for (int j = 0; j < INPUT_SIZE; j++) {\n",
        "            hidden_weights[j][i] -= LEARNING_RATE * error * input[j];\n",
        "        }\n",
        "        hidden_bias[i] -= LEARNING_RATE * error;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Initialize neural network parameters\n",
        "    // (Initialization code omitted for brevity)\n",
        "\n",
        "    // Dummy input (for demonstration purposes)\n",
        "    for (int i = 0; i < INPUT_SIZE; i++) {\n",
        "        input[i] = (float)(rand()) / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Dummy target output (for demonstration purposes)\n",
        "    float target[OUTPUT_SIZE] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0};\n",
        "\n",
        "    // Timing code\n",
        "    clock_t start_time = clock();\n",
        "\n",
        "    // Perform multiple iterations of forward and backward passes\n",
        "    for (int iter = 0; iter < ITERATIONS; iter++) {\n",
        "        forward_pass();\n",
        "        backward_pass(target);\n",
        "    }\n",
        "\n",
        "    clock_t end_time = clock();\n",
        "    double total_time = (double)(end_time - start_time) / CLOCKS_PER_SEC;\n",
        "    printf(\"Total time: %f seconds\\n\", total_time);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ hello.cpp -o hello\n",
        "!./hello"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fUCii77DpzVk",
        "outputId": "cfd51c5e-babd-4306-9ea8-42501c57c398"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 4.000668 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aKXHY7Hlqclx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}